{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K- Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem statement :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a machine learning model to predict whether a person makes over 50K a year or not\n",
    "        https://drive.google.com/open?id=1XVi34snXnh6qW2u71jwc05oCRnpOXoWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "\n",
    "#importing pandas library to handel dataset\n",
    "import pandas as pd\n",
    "#importing numpy library for faster matrix calculations\n",
    "import numpy as np\n",
    "#importing matplotlib for plotting data graphs\n",
    "import matplotlib.pyplot as plt\n",
    "#importing seaborn advanced plotting library\n",
    "import seaborn as sns\n",
    "\n",
    "#loading data set\n",
    "data_set = pd.read_csv('classification_2.csv',names=[\n",
    "\"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Marital Status\",\n",
    "\"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n",
    "\"Hours per week\", \"Country\", \"Target\"])\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for list of columns present in data set\n",
    "data_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #assigning numerical values in our target variable columns\n",
    "data_set.Target.replace([' <=50K',' >50K'],[1,0], inplace=True)\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking catagories in our target variable column and their sependency on other columns\n",
    "data_set.groupby('Target').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checking dependency of target column on workclass column <<<note only target column mean>>\n",
    "data_set.groupby('Workclass').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking dependency of target column on education column <<<note only target column mean>>\n",
    "data_set.groupby('Education').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking dependency of target column on marital status column <<<note only target column mean>>\n",
    "data_set.groupby('Marital Status').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking dependency of target column on occupation column <<<note only target column mean>>\n",
    "data_set.groupby('Occupation').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking dependency of target column on relationship column <<<note only target column mean>>\n",
    "data_set.groupby('Relationship').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking dependency of target column on race column <<<note only target column mean>>\n",
    "data_set.groupby('Race').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking dependency of target column on sex column <<<note only target column mean>>\n",
    "data_set.groupby('Sex').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checking dependency of target column on country column <<<note only target column mean>>\n",
    "data_set.groupby('Country').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting histogram to see the range and max_min count of values in data frame\n",
    "pd.DataFrame.hist(data_set, figsize = [15,15]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking catagories in our target variable column and their sependency on other columns\n",
    "data_set.groupby('Target').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for all columns\n",
    "data_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping un-necessary column from data set\n",
    "data_set.drop(['Age','fnlwgt','Education-Num','Relationship','Race','Sex','Hours per week'],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #seperating columns with catagorical data\n",
    "# #[['Workclass','Education','Marital Status', 'Occupation', 'Relationship', 'Race', 'Sex','Country']\n",
    "# # making one hot encodings for all columns\n",
    "# dummy_1 = data_set[\"Workclass\"].str.get_dummies(\" \")\n",
    "# dummy_2 = data_set[\"Education\"].str.get_dummies(\" \")\n",
    "# dummy_3 = data_set[\"Marital Status\"].str.get_dummies(\" \")\n",
    "# dummy_4 = data_set[\"Occupation\"].str.get_dummies(\" \")\n",
    "# dummy_5 = data_set[\"Relationship\"].str.get_dummies(\" \")\n",
    "# dummy_6 = data_set[\"Race\"].str.get_dummies(\" \")\n",
    "# dummy_7 = data_set[\"Sex\"].str.get_dummies(\" \")\n",
    "# dummy_8 = data_set[\"Country\"].str.get_dummies(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cols in dummy_1.columns:\n",
    "#     data_set[cols]=dummy_1[cols]\n",
    "# for cols in dummy_2.columns:\n",
    "#     data_set[cols]=dummy_2[cols]\n",
    "# for cols in dummy_3.columns:\n",
    "#     data_set[cols]=dummy_3[cols]\n",
    "# for cols in dummy_4.columns:\n",
    "#     data_set[cols]=dummy_4[cols]\n",
    "# for cols in dummy_5.columns:\n",
    "#     data_set[cols]=dummy_5[cols]\n",
    "# for cols in dummy_6.columns:\n",
    "#     data_set[cols]=dummy_6[cols]\n",
    "# for cols in dummy_7.columns:\n",
    "#     data_set[cols]=dummy_7[cols]\n",
    "# for cols in dummy_8.columns:\n",
    "#     data_set[cols]=dummy_8[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handling categorical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing all catagorical data into numerical data\n",
    "\n",
    "#these are the column having catagorical data\n",
    "catagorical_columns =['Workclass','Education','Marital Status', 'Occupation','Country']\n",
    "\n",
    "#looping through all columns\n",
    "for column in catagorical_columns:\n",
    "    value =0\n",
    "    # sorting ccatories of the column\n",
    "    categories = sorted(data_set[column].unique())\n",
    "    for category in categories:\n",
    "        data_set.loc[data_set[column] == category, column] = value\n",
    "        value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting heatmap from given data set for better view\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(data_set.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making rescaling function\n",
    "def rescaling(col):\n",
    "    max_value  = data_set[col].min()\n",
    "    min_value  = data_set[col].max()\n",
    "    data_set[col] = (data_set[col] - min_value)*10/(max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescaling capital gain and capital loss column\n",
    "rescaling('Capital Gain')\n",
    "rescaling('Capital Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describing data set \n",
    "data_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting train and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting 70 % dataset into train set & 30 % dataset into dataset into test set\n",
    "\n",
    "# selecting random 0.7 fraction of dataset as train set\n",
    "train = data_set.sample(frac=0.7, random_state=3)   \n",
    "\n",
    "# chossing different random state will give different random rows\n",
    "# selecting remaining i.e. 30% as test set\n",
    "test = data_set.drop(train.index)  \n",
    "\n",
    "#printing train data set shape and it's head values\n",
    "print(\"shape of train data : \",train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing test data set shape and it's head values\n",
    "print(\"shape of test data : \",test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_x_y(data):   \n",
    "    #seperating x values\n",
    "    y_values = np.array(data['Target'])\n",
    "    #seperating y values\n",
    "    x_values = np.ones((1,len(data)))\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if col != 'Target':\n",
    "            new_row = np.array(data[col]).reshape(1,len(data))\n",
    "            x_values = np.append(x_values, new_row, axis=0)\n",
    "\n",
    "    return x_values, y_values\n",
    "\n",
    "#obtaining x-train,x-test,y-train,y-test values by calling above function\n",
    "train_x_values, train_y_values = split_train_test_x_y(train)\n",
    "test_x_values, test_y_values = split_train_test_x_y(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking all the details about train and test data sets\n",
    "#making sure everything is right\n",
    "print(train_x_values.shape)\n",
    "print(train_y_values.shape)\n",
    "print(test_x_values.shape)\n",
    "print(test_y_values.shape)\n",
    "print(len(test_y_values),len(train_y_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building knn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for KNN model we'll take euclidean distance calculation technique for the distance evaluation\n",
    "#defining method to calculate distance for given row \n",
    "def find_distance(row,data_set):\n",
    "    #substracting element wise\n",
    "    temp_value=data_set-row\n",
    "    #squaring element wise\n",
    "    squared_value = temp_value**2\n",
    "    #returning the distance from each row\n",
    "    return np.array([row.sum() for row in squared_value])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will return true / false values based on distance and voting technique\n",
    "def find_knn(row,data_set,test_set,knn):\n",
    "    #obtaining distance of each row with every row in data set\n",
    "    distance                 = find_distance(data_set=data_set,row=data_set[row])\n",
    "    #making a temerory data frame to store lable wise distance with their target value\n",
    "    temp_distance_data_frame = pd.DataFrame({'Distances':distance, 'Target':test_set})\n",
    "    # choosing nearest k neighbours\n",
    "    knn_value =  temp_distance_data_frame.sort_values('Distances')[:knn]\n",
    "    # returning boolean value for target variable- category 1 or not(using voting of nearest k neighbours)\n",
    "    return (knn_value['Target'].sum() > (knn/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is a runner method for above two methods \n",
    "#which will store an array of true false values \n",
    "def get_knn_values(data_set,test_set):\n",
    "    #making an empty list to append values\n",
    "    all_true_false_position = []\n",
    "    #looping through each row in data set\n",
    "    for row in range(len(data_set.T)):\n",
    "        #appending values \n",
    "        all_true_false_position.append(find_knn(row,data_set.T,test_set,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predicted_values = get_knn_values(train_x_values,train_y_values)\n",
    "test_predicted_values  = get_knn_values(test_x_values,test_y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise_on_y(y_values):\n",
    "    return np.where(y_values == True, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorise each record to it's category\n",
    "train_predicted_values = categorise_on_y(train_predicted_values)\n",
    "test_predicted_values = categorise_on_y(test_predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_accuracy(predicted_values, actual_values):\n",
    "    return (predicted_values == actual_values).mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train_set = find_accuracy(train_predicted_values, train_y_values)\n",
    "accuracy_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test_set = find_accuracy(test_predicted_values, test_y_values)\n",
    "accuracy_test_set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
